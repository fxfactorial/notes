# Materialize

Naiad (Timely Dataflow), Incremental Dataflow, and Materialize are a family
of streaming database systems that combine low-latency stream processing with
iterative and incremental computation.

## Naiad: A Timely Dataflow System

Naiad is a distributed analytics database that can best be thought of an
intersection between Kafka and Hadoop. It takes in streams of data and
materializes incremental views on the data. The internal data forms a cyclic,
directed graph.

### Features

It provides the following features:

1. Structured loops (for low latency)
2. Stateful data processors that can process data without global locks (for
   low latency)
3. Notifications when processing is complete (for consistency)

### Pitch

What Naiad does is nothing new: similar systems can be constructed by
stitching features together. The main innovation is that it does this
_efficiently_: it's a single system that covers analytics, replacing
Kafka/Hadoop/batch processing clusters.


### Timely Dataflow

#### Vertexes (nodes in the graph)

Internally Naiad uses a directed cyclic graph of event emitter nodes
(vertexes) that send messages to each other (edges). There are several kinds
of nodes:

1. input: receives a sequence of messages from an external producer
2. output: emits a sequence of messages back to an external consumer

Input and output vertexes will send a message when no more events for a given
epoch will be sent. Or will send a "close" event when no more messages of
_any_ epoch will be sent. Input vertexes are driven by external sources that
provide the epoch, and "close" event, so it's mostly a way to propagate this
through the system.

#### Epochs

Epoch labels are integers and are generated by external producers and sent to
the input nodes.

#### Cycles

Vertexes are organized into _loop contexts_. There are 3 kinds of nodes that
makes up a loop context:

- __ingress node:__ messages going into the context are received here
- __egress node:__ messages leaving the context are sent from here
- __feedback node:__ messages in the context are processed here

Contexts can be nested, but each context must have a __feedback node_ so that
it does work. No empty contexts!

Each message has a timestamp that keeps track of the epoch, and the loop
contexts. That way it can keep track of the current generation, and how it's
progressed throughout the system.

```txt
epoch-[(counter for loop context), ...more counters]
```

Timestamps work like a stack: ingress nodes push a zero to the array.
Feedback nodes increment the counter by 1. Egress nodes pop the latest value
from the array. Put together with the other rules it ensures we always know
how far we are in our graph processing.

- ingress: pushed a `0` to the counter array
- egress: pops the latest value from the counter array
- feedback: increments the latest value of the counter array by 1
